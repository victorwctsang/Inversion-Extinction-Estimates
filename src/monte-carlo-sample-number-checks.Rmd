---
title: "Monte Carlo Sample Calculations"
author: "Victor Tsang (z5209633)"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

knitr::knit_hooks$set(timeit = local({
  now = NULL
  function(before, options) {
    if (before) {
      now <<- Sys.time()
    } else {
      res = difftime(Sys.time(), now)
      now <<- NULL
      # use options$label if you want the chunk label as well
      paste('Time for this code chunk:', as.character(res))
    }
  }})
)
```

#### Setup

Source our helper functions and set our parameters.

```{r}
source("new-method-functions.R")

set.seed(2022)

n = 30                             # Number of fossil samples in each dataset
theta.true = 10000                 # True extinction date
K = 20000                          # Upper bound for fossil ages
 
dating_error.mean = 0              # True mean of radiocarbon dating error
dating_error.sd = 272              # True Standard deviation
 
alpha = 0.05                       # 95% confidence interval
```

Then, simulate some data

```{r}
W = runif(n=n, min=theta.true, max=K) + rnorm(n=n, mean=dating_error.mean, sd=dating_error.sd)
m=min(W)
m
```

**Goal:** Find an expression for the variance of our estimator. We have:

$$
\begin{align*}
    q^{-\frac{1}{n}} &= 1 - \frac{F_\varepsilon(m - {\theta}_q)}{F_\varepsilon(K - {\theta}_q)} + \frac{\phi}{F_\varepsilon(K - {\theta}_q)}; &\phi =  \int^{m-\theta_q}_{-\infty} \frac{K - m}{K - e - \theta_q } f_\varepsilon(e) de
\end{align*}
$$

**(1)** --- Since $\hat\phi = \frac{1}{B} \sum_{b=1}^B \frac{K-m}{K-e_b-\theta_q}$ is a sample mean of $\phi$, we can apply the central limit theorem:

$$
\sqrt{B} \Big[ \hat\phi - \phi \Big] \overset{D}{\sim} \mathcal{N}\Big(0, \mathrm{Var}(\phi) \Big)
$$

**(2)** --- Applying the delta method, we get the asymptotic distribution of $\hat\theta$:

$$
\sqrt{B} \Big[ \hat\theta - \theta \Big] \overset{D}{\sim} \mathcal{N}\left(0,\mathrm{Var}(\phi) \cdot \left[\frac{d}{d\theta} \phi \right]^{-2} \right) 
\implies \mathrm{Var}\{\hat{\theta}_q\} = \frac{\mathrm{Var}(\phi)}{\left[\frac{d}{d\theta} \phi \right]^{2}} \approx \frac{\mathrm{Var}(\hat\phi)}{\left[\frac{d}{d\theta} \phi\right]^{2}}
$$

**(3)** --- $\mathrm{Var}(\hat\phi)$

$$
\begin{align*}
    \mathrm{Var}(\hat\phi)
        &= \mathrm{Var}\left\{\frac{1}{B} \sum_{b=1}^B \frac{K-m}{K-e_b-\theta_q} \right\} \\
        &= \frac{1}{B} {\mathrm{Var}\left\{ \frac{K-m}{K-e-\theta_q} \right\}} \\
        &\approx \frac{1}{B} \mathrm{Var}\left\{ \frac{K-m}{K-e-\hat\theta_q} \right\} = \frac{1}{B} \sigma_\phi^2
\end{align*}
$$

We can estimate $\sigma_\phi^2$ for our upper and lower bounds by taking the sample variance of $\frac{K-m}{K-e-\hat\theta_q}$, where $\hat\theta_q$ is estimated using some arbitrary $B$ for our monte carlo integral.

Initial estimates of $\hat\theta_q$:

```{r}
B = 500                            # Arbitrary initial B (number of monte carlo samples)
u=matrix(runif(n*B, 0, 1), ncol=B) # Base MC Samples to plug into our method
uniroot.interval = c(2000, 19500)  # Search interval for uniroot (TODO - a better way of picking this?)

init.CI = estimate_CI.mc(alpha, n, K, W, u, dating_error.mean, dating_error.sd, uniroot.interval)
init.CI
```

Use this initial estimate to generate our monte carlo samples.

```{r}
e = list()
e$lower = rtnorm(n, mean=dating_error.mean, sd=dating_error.sd, a=-Inf, b=m-init.CI$CI.lower)
e$upper = rtnorm(n, mean=dating_error.mean, sd=dating_error.sd, a=-Inf, b=m-init.CI$CI.upper)
e
```

**(4)** --- $\frac{d}{d\theta} \phi$

$$
\begin{align*}
    \frac{d}{d\theta_q}  \phi
        &= \frac{d}{d\theta_q} \int^{m-\theta_q}_{-\infty} \frac{K-m}{K-e-\theta_q}f_\varepsilon(e)de \\
        &= \int^{m-\theta_q}_{-\infty} \frac{\partial}{\partial \theta_q}\frac{K-m}{K-e-\theta_q}f_\varepsilon(e)de + \frac{K-m}{K-(m-\theta_q)-\theta_q}f_\varepsilon(m-\theta_q)(-1) - 0 \\
        &= \int^{m-\theta_q}_{-\infty} \frac{K-m}{(K-e-\theta_q)^2}f_\varepsilon(e)de - f_\varepsilon(m-\theta_q) \\
        &\approx \frac{1}{B} \sum_{b=1}^B\frac{K-m}{(K-e_b-\hat\theta_q)^2} - f_\varepsilon(m-\hat\theta_q)
\end{align*}
$$

**(5)** --- Put it all together:

$$
\mathrm{Var}\{\hat{\theta}_q\}
    \approx \frac{1}{B} \mathrm{Var}\left\{ \frac{K-m}{K-e-\hat\theta_q}
        \right\} \left[ \frac{1}{B} \sum_{b=1}^B\frac{K-m}{(K-e_b-\hat\theta_q)^2} - f_\varepsilon(m-\hat\theta_q) \right]^{-2}
$$

$$
\implies B
    \approx \left[\mathrm{Var}\{\hat{\theta}_q\}\right]^{-1} \mathrm{Var}\left\{ \frac{K-m}{K-e-\hat\theta_q}         \right\} \left[ \frac{1}{B} \sum_{b=1}^B\frac{K-m}{(K-e_b-\hat\theta_q)^2} - f_\varepsilon(m-\hat\theta_q) \right]^{-2}
$$

Using the $\sigma_\phi^2$ we estimated earlier and an arbitrary target $\mathrm{Var}\{\hat\theta_q\} = 0.2*\sigma^2$, we can use the above formula to find an estimate of the optimal $B$

```{r}
find_optimal_B.phi = function (var.theta, theta, K, m, e, eps.mean, eps.sigma) {
  var.theta^(-1) * var((K - m)/(K-e-theta)* pnorm(m-theta, eps.mean, eps.sigma)) * ( mean((K-m)/(K-e-theta)^2)* pnorm(m-theta, eps.mean, eps.sigma) - dnorm(m-theta) )^(-2)
}
```

```{r}
var.theta.target = (0.05*dating_error.sd)^2

optimal_B.phi = list()
optimal_B.phi$lower = find_optimal_B.phi(var.theta=var.theta.target,
                                         theta=init.CI$CI.lower,
                                         K, m, e$lower,
                                         dating_error.mean,
                                         dating_error.sd)

optimal_B.phi$upper = find_optimal_B.phi(var.theta=var.theta.target,
                                         theta=init.CI$CI.upper,
                                         K, m, e$upper,
                                         dating_error.mean,
                                         dating_error.sd)
optimal_B.phi
```

What if used $\psi$ instead of $\phi$?

$$
\implies B
    \approx \left[\mathrm{Var}\{\hat{\theta}_q\}\right]^{-1}  \underbrace{ \mathrm{Var}\left\{\frac{m-e-\hat\theta_q}{K-e-\hat\theta_q} \right\}}_{\sigma^2_\psi} \left[ \underbrace{\frac{1}{B} \sum_{b=1}^B\frac{m-K}{(K-e_b-\hat\theta_q)^2}}_{d\psi/d\hat\theta_q} \right]^{-2}
$$

```{r}
find_optimal_B.psi = function (var.theta, theta, K, m, e, eps.mean, eps.sigma) {
  sigma2.psi = var((m-e-theta)/(K-e-theta)* pnorm(m-theta, eps.mean, eps.sigma))
  dpsi.dtheta = mean((m-K)/(K-e-theta)^2) * pnorm(m-theta, eps.mean, eps.sigma)

  var.theta^(-1) * sigma2.psi * dpsi.dtheta^(-2)
  # var.theta * sigma2.psi^(-1) * (sum((m-K)/(K-e-theta)^2) * pnorm(m-theta, eps.mean, eps.sigma))^2
}
```

```{r timeit = TRUE}
optimal_B.psi = list()
optimal_B.psi$lower = find_optimal_B.psi(var.theta=var.theta.target,
                                         theta=init.CI$CI.lower,
                                         K, m, e$lower,
                                         dating_error.mean,
                                         dating_error.sd)

optimal_B.psi$upper = find_optimal_B.psi(var.theta=var.theta.target,
                                         theta=init.CI$CI.upper,
                                         K, m, e$upper,
                                         dating_error.mean,
                                         dating_error.sd)
optimal_B.psi
```

**TODO** ok lets just find sample variance at different B's empirically

**TODO** why are the numbers so weird??

## Checks

Three things to check expected behaviour:

$$
\mathrm{Var}(\hat\theta_q), \quad \mathrm{Var}\left\{ \frac{m-e-\hat\theta_q}{K-e-\hat\theta_q} \right\}, \quad \left[ \frac{1}{B} \sum_{b=1}^B\frac{m-K}{(K-e_b-\hat\theta_q)^2} \right]^{-2}
$$

### Variance of $\hat\theta_q$

For the purposes of this check, we'll only look at the lower bound estimate.

```{r, timeit = TRUE}
n = 30

num.B = 30
B = seq(from=2, by=50, length.out=num.B)

num.estimates = 100

# Simulate a dataset
W = runif(n=n, min=theta.true, max=K) + rnorm(n=n, mean=dating_error.mean, sd=dating_error.sd)
m=min(W)

var.theta_q = list()
var.theta_q$lower = rep(NA, num.B)
var.theta_q$upper = rep(NA, num.B)

u = matrix(runif(n*num.estimates*B[num.B], min=0, max=1), ncol=B[num.B])
```

```{r, timeit=TRUE, cache=TRUE}
for (i in 1:num.B) {
  # Generate 100 estimates of \theta_0.025
  theta.hat.lower = rep(NA, num.estimates)
  theta.hat.upper = rep(NA, num.estimates)
  for (j in 1:num.estimates) {
    theta.hat.lower[j] = estimate_quantile.mc(q=0.025, K, W, u[((j-1)*n+1):((j)*n), 1:(B[i])], 
                                              dating_error.mean, 
                                              dating_error.sd, uniroot.interval)
    theta.hat.upper[j] = estimate_quantile.mc(q=0.975, K, W, u[((j-1)*n+1):((j)*n), 1:(B[i])], 
                                              dating_error.mean, 
                                              dating_error.sd, uniroot.interval)
  }
  # save sample variance
  var.theta_q$lower[i] = var(theta.hat.lower)
  var.theta_q$upper[i] = var(theta.hat.upper)
}
```

```{r}
plot(B, var.theta_q$lower, type="l", col='blue', 
     log = "xy", 
     main="Sample Var(theta_q) against Number of MC Samples",
     ylab=paste("sample variance"), 
     ylim=c(min(c(var.theta_q$lower, var.theta_q$upper)), max(c(var.theta_q$lower, var.theta_q$upper))))
lines(B, var.theta_q$upper, type="l", col='red')
# abline(v=optimal_B.psi$lower, lty=2, col='blue')
# abline(v=optimal_B.psi$upper, lty=2, col='red')
# abline(h=var.theta.target, lty=2)
legend("topright",
       c("q=0.025", "q=0.975"),
       lty=c(1, 1),
       col=c('blue', 'red'))
```

### $\mathrm{Var}\left\{ \frac{m-e-\hat\theta_q}{K-e-\hat\theta_q} \right\}$

```{r}
num.mc_samples = 1000
num.estimates = 1000

sigma2_psi = rep(NA, num.estimates)
for (i in 1:num.estimates) {
  # Get B samples of e
  e = extraDistr::rtnorm(n=num.mc_samples, mean=dating_error.mean, sd=dating_error.sd, a=-Inf, b=m-init.CI$CI.lower)
  
  sigma2_psi[i] = var((m-e-init.CI$CI.lower)/(K-e-init.CI$CI.lower)* pnorm(m-init.CI$CI.lower, dating_error.mean, dating_error.sd))
}

hist(sigma2_psi, main="Histogram of Var(psi)")
qqnorm(sigma2_psi, pch = 1, frame = FALSE)
qqline(sigma2_psi, col = "steelblue", lwd = 2)
```


### \left[ \frac{1}{B} \sum_{b=1}^B\frac{m-K}{(K-e_b-\hat\theta_q)^2} \right]^{-2}

```{r}
num.mc_samples = 1000
num.estimates = 1000

dpsi.dtheta = rep(NA, num.estimates)
for (i in 1:num.estimates) {
  # Get B samples of e
  e = extraDistr::rtnorm(n=num.mc_samples, mean=dating_error.mean, sd=dating_error.sd, a=-Inf, b=m-init.CI$CI.lower)
  
  dpsi.dtheta[i] = mean((m-e-init.CI$CI.lower)/(K-e-init.CI$CI.lower)^2* pnorm(m-init.CI$CI.lower, dating_error.mean, dating_error.sd))
}

plot(dpsi.dtheta)
```

## From before:

### $\sigma^2_\phi = \mathrm{Var}\left(\frac{K-m}{K-e-\hat\theta_q}\right)$

$$
\quad \mathrm{Var}\left\{ \frac{K-m}{K-e-\theta_q} \right\}, \quad \left[(1-q^{-1/n}) f_\varepsilon(K - \hat{\theta}_q) - f_\varepsilon(m - \hat{\theta}_q) \right]^{-2}
$$

2.  Take 1000 different sets of monte carlo samples of size $B$ and calculate the sample variance of $\frac{K-m}{K-e-\hat\theta_q}$. What is the range? What's the variance of our variance estimate?
3.  How does $\left[(1-q^{-1/n}) f_\varepsilon(K - \hat{\theta}_q) - f_\varepsilon(m - \hat{\theta}_q) \right]^{-2}$ change with $q$? How about relative to $\hat\theta_q$, fixing everything else?

```{r}
num.mc_samples = 1000
num.estimates = 1000

sigma2_phi = rep(NA, num.estimates)
for (i in 1:num.estimates) {
  # Get B samples of e
  e = extraDistr::rtnorm(n=num.mc_samples, mean=dating_error.mean, sd=dating_error.sd, a=-Inf, b=m-init.CI$CI.lower)
  
  sigma2_phi[i] = var((K-m)/(K-e-init.CI$CI.lower))
}
mean(sigma2_phi)
var(sigma2_phi)

plot(sigma2_phi)
boxplot(sigma2_phi)
```

### Weird term

$$
\left[(1-q^{-1/n}) f_\varepsilon(K - \hat{\theta}_q) - f_\varepsilon(m - \hat{\theta}_q) \right]^{-2}
$$

```{r}
set.seed(2022)
n = 30
B = 200
u = matrix(runif(n*B, min=0, max=1), ncol=B)

q = seq(from=0.025, to=0.975, by=0.025)
theta_q = rep(NA, length(q))
term = rep(NA, length(q))
for (i in 1:length(q) ) {
  # estimate theta_q
  theta_q[i] = estimate_quantile.mc(q=q[i], K, W, u, dating_error.mean, 
                               dating_error.sd, c(5000, 19500))
  term[i] = ( (1 - q[i]^(-1/n)) * dnorm(K - theta_q[i], dating_error.mean, dating_error.sd) - dnorm(m - theta_q[i], dating_error.mean, dating_error.sd) )^(-2)
}

plot(x=q, y=term, type="b", log="y")
```

```{r}
log(term)
```

```{r}
m-theta_q
dnorm(m - theta_q, dating_error.mean, dating_error.sd)
```

Conclusion: using the term with $q$ in it is causing $B$ to explode.