---
title: "Monte Carlo Sample Calculations"
author: "Victor Tsang (z5209633)"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

knitr::knit_hooks$set(timeit = local({
  now = NULL
  function(before, options) {
    if (before) {
      now <<- Sys.time()
    } else {
      res = difftime(Sys.time(), now)
      now <<- NULL
      # use options$label if you want the chunk label as well
      paste('Time for this code chunk:', as.character(res))
    }
  }})
)
```

#### Setup

Source our helper functions and set our parameters.

```{r}
source("new-method-functions.R")

set.seed(2022)

n = 30                             # Number of fossil samples in each dataset
theta.true = 10000                 # True extinction date
K = 20000                          # Upper bound for fossil ages
 
dating_error.mean = 0              # True mean of radiocarbon dating error
dating_error.sd = 272              # True Standard deviation
 
alpha = 0.05                       # 95% confidence interval
```

Then, simulate some data

```{r}
W = runif(n=n, min=theta.true, max=K) + rnorm(n=n, mean=dating_error.mean, sd=dating_error.sd)
m=min(W)
m
```


$$
\implies B
    \approx \left[\mathrm{Var}\{\hat{\theta}_q\}\right]^{-1} \mathrm{Var} \left\{ \frac{m - e_1^* - \hat\theta_q}{K - e_1^* - \hat\theta_q } \right\} \left[ F_\varepsilon (m - \hat\theta_q) \right]^2 \left[ - \frac{f_\varepsilon (K - \hat\theta_q)}{F_\varepsilon (K - \hat\theta_q)} \psi \right]^{-2}
$$

where $e_b^*$ are samples from distribution with $f_varepsilon(e_b)$ but right-truncated at $m-\hat\theta_q$

```{r}
find_optimal_B.psi = function (max_var, q, K, m, eps.mean, eps.sigma, B=500) {
  # Initial estimate of theta_q using no measurement error case
  theta_q.hat.init = K - q^(-1/n)*(K-m) 
  
  # Monte carlo samples
  e = rtnorm(B, mean=eps.mean, sd=eps.sigma, a=-Inf, b=m-theta_q.hat.init)
  
  f_eps.K = dnorm(K-theta_q.hat.init, eps.mean, eps.sigma)
  F_eps.K = pnorm(K-theta_q.hat.init, eps.mean, eps.sigma)
  f_eps.m = dnorm(m-theta_q.hat.init, eps.mean, eps.sigma)
  F_eps.m = pnorm(m-theta_q.hat.init, eps.mean, eps.sigma)
  
  sigma2.psi_hat = var((m-e-theta_q.hat.init)/(K-e-theta_q.hat.init))
  psi_hat = mean((m-e-theta_q.hat.init)/(K-e-theta_q.hat.init)) * F_eps.m
  dpsi_hat.dtheta =  -f_eps.m/F_eps.m * psi_hat

  max_var^(-1) * sigma2.psi_hat * F_eps.m^2 * dpsi_hat.dtheta^(-2)
}
```

```{r timeit = TRUE}
var.theta.target = (0.2*dating_error.sd)^2

optimal_B.psi = list()
optimal_B.psi$lower = find_optimal_B.psi(max_var=var.theta.target,
                                         q=0.025,
                                         K, m,
                                         dating_error.mean,
                                         dating_error.sd)

optimal_B.psi$upper = find_optimal_B.psi(max_var=var.theta.target,
                                         q=0.975,
                                         K, m,
                                         dating_error.mean,
                                         dating_error.sd)
optimal_B.psi
```

**TODO** ok lets just find sample variance at different B's empirically

**TODO** why are the numbers so weird??

## Checks

Three things to check expected behaviour:

$$
\mathrm{Var}(\hat\theta_q), \quad \mathrm{Var}\left\{ \frac{m-e-\hat\theta_q}{K-e-\hat\theta_q} \right\}, \quad \left[ \frac{1}{B} \sum_{b=1}^B\frac{m-K}{(K-e_b-\hat\theta_q)^2} \right]^{-2}
$$

### Variance of $\hat\theta_q$

For the purposes of this check, we'll only look at the lower bound estimate.

```{r, timeit = TRUE}
n = 30

num.B = 30
B = seq(from=2, by=50, length.out=num.B)

num.estimates = 100

# Simulate a dataset
W = runif(n=n, min=theta.true, max=K) + rnorm(n=n, mean=dating_error.mean, sd=dating_error.sd)
m=min(W)

var.theta_q = list()
var.theta_q$lower = rep(NA, num.B)
var.theta_q$upper = rep(NA, num.B)

u = matrix(runif(n*num.estimates*B[num.B], min=0, max=1), ncol=B[num.B])
```

```{r, timeit=TRUE, cache=TRUE}
for (i in 1:num.B) {
  # Generate 100 estimates of \theta_0.025
  theta.hat.lower = rep(NA, num.estimates)
  theta.hat.upper = rep(NA, num.estimates)
  for (j in 1:num.estimates) {
    theta.hat.lower[j] = estimate_quantile.mc(q=0.025, K, W, u[((j-1)*n+1):((j)*n), 1:(B[i])], 
                                              dating_error.mean, 
                                              dating_error.sd, uniroot.interval)
    theta.hat.upper[j] = estimate_quantile.mc(q=0.975, K, W, u[((j-1)*n+1):((j)*n), 1:(B[i])], 
                                              dating_error.mean, 
                                              dating_error.sd, uniroot.interval)
  }
  # save sample variance
  var.theta_q$lower[i] = var(theta.hat.lower)
  var.theta_q$upper[i] = var(theta.hat.upper)
}
```

```{r}
options(scipen = 100)
B = seq(from=2, by=50, length.out=num.B)
plot(B, var.theta_q$lower, type="b", col='blue', 
     log = "xy", 
     main="Sample Var(theta_q) against Number of MC Samples",
     ylab=paste("sample variance"), 
     ylim=c(min(c(var.theta_q$lower, var.theta_q$upper)), max(c(var.theta_q$lower, var.theta_q$upper))))
lines(B, var.theta_q$upper, type="b", col='red')
abline(h=var.theta.target, lty=2, col='green')
legend("topright",
       c("q=0.025", "q=0.975"),
       lty=c(1, 1),
       col=c('blue', 'red'))

# Add lines for our target variance and optimal B's calculated previously
# abline(v=c(optimal_B.psi$lower, optimal_B.psi$upper), lty=2, col=c("blue", "red"))
# abline(h=6, lty=2)
```

### $\mathrm{Var}\left\{ \frac{m-e-\hat\theta_q}{K-e-\hat\theta_q} \right\}$

```{r}
num.mc_samples = 1000
num.estimates = 1000

sigma2_psi = rep(NA, num.estimates)
for (i in 1:num.estimates) {
  # Get B samples of e
  e = extraDistr::rtnorm(n=num.mc_samples, mean=dating_error.mean, sd=dating_error.sd, a=-Inf, b=m-init.CI$CI.lower)
  
  sigma2_psi[i] = var((m-e-init.CI$CI.lower)/(K-e-init.CI$CI.lower)* pnorm(m-init.CI$CI.lower, dating_error.mean, dating_error.sd))
}

hist(sigma2_psi, main="Histogram of Var(psi)")
qqnorm(sigma2_psi, pch = 1, frame = FALSE)
qqline(sigma2_psi, col = "steelblue", lwd = 2)
```

### \left[ \frac{1}{B} \sum_{b=1}^B\frac{m-K}{(K-e_b-\hat\theta_q)^2} \right]\^{-2}

```{r}
num.mc_samples = 1000
num.estimates = 1000

dpsi.dtheta = rep(NA, num.estimates)
for (i in 1:num.estimates) {
  # Get B samples of e
  e = extraDistr::rtnorm(n=num.mc_samples, mean=dating_error.mean, sd=dating_error.sd, a=-Inf, b=m-init.CI$CI.lower)
  
  dpsi.dtheta[i] = mean((m-e-init.CI$CI.lower)/(K-e-init.CI$CI.lower)^2* pnorm(m-init.CI$CI.lower, dating_error.mean, dating_error.sd))
}

plot(dpsi.dtheta)
```

## From before:

### $\sigma^2_\phi = \mathrm{Var}\left(\frac{K-m}{K-e-\hat\theta_q}\right)$

$$
\quad \mathrm{Var}\left\{ \frac{K-m}{K-e-\theta_q} \right\}, \quad \left[(1-q^{-1/n}) f_\varepsilon(K - \hat{\theta}_q) - f_\varepsilon(m - \hat{\theta}_q) \right]^{-2}
$$

2.  Take 1000 different sets of monte carlo samples of size $B$ and calculate the sample variance of $\frac{K-m}{K-e-\hat\theta_q}$. What is the range? What's the variance of our variance estimate?
3.  How does $\left[(1-q^{-1/n}) f_\varepsilon(K - \hat{\theta}_q) - f_\varepsilon(m - \hat{\theta}_q) \right]^{-2}$ change with $q$? How about relative to $\hat\theta_q$, fixing everything else?

```{r}
num.mc_samples = 1000
num.estimates = 1000

sigma2_phi = rep(NA, num.estimates)
for (i in 1:num.estimates) {
  # Get B samples of e
  e = extraDistr::rtnorm(n=num.mc_samples, mean=dating_error.mean, sd=dating_error.sd, a=-Inf, b=m-init.CI$CI.lower)
  
  sigma2_phi[i] = var((K-m)/(K-e-init.CI$CI.lower))
}
mean(sigma2_phi)
var(sigma2_phi)

plot(sigma2_phi)
boxplot(sigma2_phi)
```

### Weird term

$$
\left[(1-q^{-1/n}) f_\varepsilon(K - \hat{\theta}_q) - f_\varepsilon(m - \hat{\theta}_q) \right]^{-2}
$$

```{r}
set.seed(2022)
n = 30
B = 200
u = matrix(runif(n*B, min=0, max=1), ncol=B)

q = seq(from=0.025, to=0.975, by=0.025)
theta_q = rep(NA, length(q))
term = rep(NA, length(q))
for (i in 1:length(q) ) {
  # estimate theta_q
  theta_q[i] = estimate_quantile.mc(q=q[i], K, W, u, dating_error.mean, 
                               dating_error.sd, c(5000, 19500))
  term[i] = ( (1 - q[i]^(-1/n)) * dnorm(K - theta_q[i], dating_error.mean, dating_error.sd) - dnorm(m - theta_q[i], dating_error.mean, dating_error.sd) )^(-2)
}

plot(x=q, y=term, type="b", log="y")
```

```{r}
log(term)
```

```{r}
m-theta_q
dnorm(m - theta_q, dating_error.mean, dating_error.sd)
```

Conclusion: using the term with $q$ in it is causing $B$ to explode.
