@article{Mcinerny2006,
   abstract = {We are now entering a time of immense environmental upheaval in which, increasingly, experts are required to provide conservation assessments. Quantitative assessment of trends in species' range and abundance is costly, requiring extensive field studies over a long period of time. Unfortunately, many species are only known through a few "chance" sightings or a handful of specimens, and therefore extinction may be even harder to ascertain. Several methods have been proposed for estimating the probability of extinction. However, comparison within and between species is difficult because of variations in sighting rates. We applied a probabilistic method that incorporates sighting rate to the sighting record of Viet-namese slipper orchids (Paphiopedilum). The method generates a probability that another sighting will occur given the previous sighting rate and the time since last observation. This allows greater comparability between species discovered at different times. Its predictions were more highly correlated with the World Conservation Union criteria than previous methods. Trends in data collection and the political climate of a country, which affects access to material, are important potential sources of variation that affect sighting rates. A lack of understanding of the process by which data are generated makes inferring extinction from sighting records difficult because extinction status depends on how the sighting rate varies. However, such methods allow rapid conservation prioritization of taxa that are poorly known and would otherwise go unassessed. Significado de la Tasa de Avistamiento en la Inferencia de Extinción y Amenaza Resumen: Estamos comenzando un tiempo de gran conmoción por el ambiente en el cual se requiere cada vez más que los expertos proporcionen evaluaciones de conservación. La evaluación cuantitativa de las tendencias en la distribución y abundancia de las especies es muy costosa, ya que requiere de estudios de campo extensivos durante un largo período de tiempo. Desafortunadamente, muchas especies solo son conocidas por medio de unos cuantos avistamientos "fortuitos" o un puñado de especimenes, y por lo tanto la verificación de extinciones es aun más difícil. Se han propuesto varios métodos para estimar la probabilidad de extinción, Sin embargo, la comparación dentro y entre especies es difícil por las variaciones en las tasas de avistamiento. Aplicamos un método probabilístico que incorpora la tasa de avistamiento al registro de avistamientos de orquídeas vietnamitas (Paphiopedilum). El método genera la probabilidad de que ocurra otro avistamiento en función de la tasa de avistamiento previa y el tiempo desde lá ultima observación. Esto permite mayor compatibilidad entre especies descubiertas en tiempos diferentes. Sus predicciones estuvieron más correlacionadas con los criterios de la Unión Mundial de la Conservación que con métodos previos. Las tendencias en los datos de colección y el clima político de un país, que dificulta el acceso al material, son importantes fuentes potenciales de variación que afectan a las tasas de avistamiento. La falta de entendimiento ‡Address correspondence to D. Roberts, McInerny et al. Sighting Rate and Inferring Extinction 563 del proceso de generación de datos dificulta la inferencia de la extinción a partir de registros de avistamiento porque el estatus de extinción depende de la variación en la tasa de avistamiento. Sin embargo, tales métodos permiten la definición de prioridades de conservación de taxa que son poco conocidos y que de otra manera no serían evaluados. Palabras Clave: criterios de lista roja, datos de colección, declinación de especies, especimenes de herbario, Paphiopedilum},
   author = {Greg J Mcinerny and David L Roberts and Anthony J Davy and Phillip J Cribb},
   doi = {10.1111/j.1523-1739.2006.00377.x},
   issue = {2},
   journal = {Conservation Biology},
   keywords = {Paphiopedilum,collection data,herbarium specimens,red-list criteria,species decline},
   pages = {562-567},
   title = {Significance of Sighting Rate in Inferring Extinction and Threat},
   volume = {20},
   year = {2006},
}
@article{Brillinger1987,
   author = {David R Brillinger},
   title = {Estimating the chances of large earthquakes by radiocarbon dating and statistical modelling},
   year = {1987},
}
@article{Lee2010,
   author = {Lee Hsiang Liow and Torbjørn Ergon and Tore Schweder},
   doi = {10.1666/08080.1},
   title = {Global occurrence trajectories of microfossils: Environmental volatility and the rise and fall of individual species},
   url = {https://www.researchgate.net/publication/222711778},
   year = {2010},
}
@book{Walker2005Quaternary,
  title={Quaternary Dating Methods},
  author={Walker, M.},
  isbn={9780470869260},
  lccn={2004029171},
  url={https://books.google.com.au/books?id=KOaetfIvGZUC},
  year={2005},
  publisher={Wiley}
}

@article{Clements2013,
   author = {Christopher F. Clements and Nicholas T. Worsfold and Philip H. Warren and Ben Collen and Nick Clark and Tim M. Blackburn and Owen L. Petchey},
   doi = {https://doi.org/10.1111/1365-2656.12005},
   issue = {2},
   journal = {Journal of Animal Ecology},
   title = {Experimentally testing the accuracy of an extinction estimator: Solow's optimal linear estimation model},
   volume = {82},
   url = {https://www.jstor.org/stable/23353444#metadata_info_tab_contents},
   year = {2013},
}
@article{Mcnamara2003,
   abstract = {It is common to estimate the extinction probability for a vulnerable population using methods that are based on the mean and variance of the long-term population growth rate. The numerical values of these two parameters are estimated from time series of population censuses. However, the proportion of a population that is registered at each census is typically not constant but will vary among years because of stochastic factors such as weather conditions at the time of sampling. Here, we analyse how such sampling errors influence estimates of extinction risk and find sampling errors to produce two opposite effects. Measurement errors lead to an exaggerated overall variance, but also introduce negative autocorrelations in the time series (which means that estimates of annual growth rates tend to alternate in size). If time series data are treated properly these two effects exactly counter balance. We advocate routinely incorporating a measure of among year correlations in estimating population extinction risk.},
   author = {John M Mcnamara and Karin C Harding},
   doi = {10.1046/j.1461-0248.2003.00550.x},
   keywords = {Negative autocorrelation,population extinction risk,time series Ecology Letters (2004) 7: 16-20},
   title = {Measurement error and estimates of population extinction risk},
   year = {2003},
}
@article{Signor1982,
   abstract = {Catastrophic hypotheses for mass extinctions are commonly criticized because many taxa gradually disappear from the fossil record prior to the extinction. Presumably, a geologically instantaneous catastrophe would not cause a reduction in diversity or a series of minor extinctions before the actual mass extinction. Two types of sampling effects, however, could cause taxa to appear to decline before their actual biotic extinction. The first of these is reduced sample size provided in the sedimentary record and the second, which we examine in greater detail, is artificial range truncation. The fossil record is discontinuous in time and the recorded ranges of species or of higher taxa can only extend to their last known occurrence in the fossil record. If the distribution of last occurrences is random with respect to actual biotic extinction, then apparent extinctions will begin well before a mass extinction and will gradually increase in frequency until the mass extinction event, thus giving the appearance of a gradual extinction. Other factors, such as regressions, can exacerbate the bias toward gradual disappearance of taxa from the fossil record. Hence, gradual extinction patterns prior to a mass extinction do not necessarily eliminate catastrophic extinction hypotheses. The recorded ranges of fossils, especially of uncommon taxa or taxa in habitats not represented by a continuous record, may be inadequate to test either gradual or catastrophic hypotheses.},
   author = {Philip W. Signor and Jere H. Lipps},
   doi = {10.1130/SPE190-P291},
   issn = {00721077},
   journal = {Special Paper of the Geological Society of America},
   pages = {291-296},
   publisher = {Geological Society of America},
   title = {Sampling bias, gradual extinction patterns and catastrophes in the fossil record},
   volume = {190},
   year = {1982},
}
@article{Solow1993,
   abstract = {N.a.},
   author = {Andrew R. Solow},
   doi = {10.2307/1940821},
   issue = {3},
   journal = {Ecology},
   month = {4},
   pages = {962-964},
   publisher = {Wiley},
   title = {Inferring Extinction from Sighting Data},
   volume = {74},
   year = {1993},
}
@article{Ramsey2010,
   abstract = {Calibration is a core element of radiocarbon dating and is undergoing rapid development on a number of different fronts. This is most obvious in the area of 14C archives suitable for calibration purposes, which are now demonstrating much greater coherence over the earlier age range of the technique. Of particular significance to this end is the development of purely terrestrial archives such as those from the Lake Suigetsu sedimentary profile and Kauri tree rings from New Zealand, in addition to the groundwater records from speleothems. Equally important, however, is the development of statistical tools that can be used with, and help develop, such calibration data. In the context of sedimentary deposition, age-depth modeling provides a very useful way to analyze series of measurements from cores, with or without the presence of additional varve information. New methods are under development, making use of model averaging, that generate more robust age models. In addition, all calibration requires a coherent approach to outliers, for both single samples and where entire data sets might be offset relative to the calibration curve. This paper looks at current developments in these areas.},
   author = {Christopher Bronk Ramsey and Michael Dee and Sharen Lee and Takeshi Nakagawa and Richard A. Staff},
   doi = {10.1017/S0033822200046063},
   issn = {0033-8222},
   issue = {3},
   journal = {Radiocarbon},
   pages = {953-961},
   publisher = {Cambridge University Press},
   title = {Developments in the Calibration and Modeling of Radiocarbon Dates},
   volume = {52},
   url = {https://www.cambridge.org/core/journals/radiocarbon/article/developments-in-the-calibration-and-modeling-of-radiocarbon-dates/435019361F06226567E0D9FBE882594D},
   year = {2010},
}
@article{Solow2005,
   author = {Andrew R. Solow},
   doi = {10.1016/j.mbs.2005.02.001},
   issn = {00255564},
   issue = {1},
   journal = {Mathematical Biosciences},
   month = {5},
   pages = {47-55},
   title = {Inferring extinction from a sighting record},
   volume = {195},
   year = {2005},
}
@article{Joelle2020,
   author = {Joëlle Barido-Sottani and Nina M. A. van Tiel and Melanie J. Hopkins and David F. Wright and Tanja Stadler and Rachel C. M. Warnock},
   doi = {10.3389/fevo.2020.00183},
   issn = {2296-701X},
   journal = {Frontiers in Ecology and Evolution},
   month = {6},
   title = {Ignoring Fossil Age Uncertainty Leads to Inaccurate Topology and Divergence Time Estimates in Time Calibrated Tree Inference},
   volume = {8},
   year = {2020},
}
@article{Fu2015,
   abstract = {This chapter reviews simulation-based methods for estimating gradients, which are central to gradient-based simulation optimization algorithms such as stochastic approximation and sample average approximation.We begin by describing approaches based on finite differences, including the simultaneous perturbation method. The remainder of the chapter then focuses on the direct gradient estimation techniques of perturbation analysis, the likelihood ratio/score function method, and the use of weak derivatives (also known as measure-valued differentiation). Various examples are provided to illustrate the different estimators—for a single random variable, a stochastic activity network, and a single-server queue. Recent work on quantile sensitivity estimation is summarized, and several newly proposed approaches for using stochastic gradients in simulation optimization are discussed.},
   author = {Michael C. Fu},
   doi = {10.1007/978-1-4939-1384-8_5},
   issn = {08848289},
   journal = {International Series in Operations Research and Management Science},
   pages = {105-147},
   publisher = {Springer New York LLC},
   title = {Stochastic gradient estimation},
   volume = {216},
   year = {2015},
}
@article{Chau2015,
   abstract = {This chapter provides an overview of stochastic approximation (SA) methods in the context of simulation optimization. SA is an iterative search algorithm that can be viewed as the stochastic counterpart to steepest descent in deterministic optimization.We begin with the classical methods of Robbins–Monro (RM) and Kiefer–Wolfowitz (KW). We discuss the challenges in implementing SA algorithms and present some of the most well-known variants such as Kesten’s rule, iterate averaging, varying bounds, and simultaneous perturbation stochastic approximation (SPSA), as well as recently proposed versions including scaledand- shifted Kiefer–Wolfowitz (SSKW), robust stochastic approximation (RSA), accelerated stochastic approximation (AC-SA) for convex and strongly convex functions, and Secant-Tangents AveRaged stochastic approximation (STAR-SA). We investigate the empirical performance of several of the recent algorithms by comparing them on a set of numerical examples.},
   author = {Marie Chau and Michael C. Fu},
   doi = {10.1007/978-1-4939-1384-8_6},
   issn = {08848289},
   journal = {International Series in Operations Research and Management Science},
   pages = {149-178},
   publisher = {Springer New York LLC},
   title = {An overview of stochastic approximation},
   volume = {216},
   year = {2015},
}
@article{Strauss1989,
   abstract = {The observed local range of a fossil taxon in a stratigraphic section is almost certainly a truncated version of the true local range. True endpoints are parameters that may be estimated using only the assumption that fossil finds are distributed randomly between them. If thickness is rescaled so that true endpoints lie at 0 and 1, the joint distribution of gap lengths between fossil finds is given by the Dirichlet distribution. Observed ends of the range are maximum likelihood estimators of true endpoints, but they are biased seriously. Extension of the observed range at each end by a distance equal to the average gap length yields unbiased point estimators. Classical statistics can generate confidence intervals for ends of the taxon range; but with Bayesian inference, the probability that true endpoints lie in a certain region can be stated. For a 95\% confidence level (classical) or a 95\% probability (Bayesian), the range extensions exceed the observed range if the range is established on less than six finds; if only two finds are used, such range extensions are an order of magnitude longer than the observed range. Evidently the standard biostratigraphic practice that identifies zonal boundaries as horizons rather than confidence intervals may not be justified at the resolution of typical fossiliferous sections.},
   author = {David Strauss and Peter M. Sadler},
   doi = {10.1007/BF00897326},
   issn = {1573-8868},
   issue = {4},
   journal = {Mathematical Geology 1989 21:4},
   keywords = {Chemistry and Earth Sciences,Computer Science,Earth Sciences,Geotechnical Engineering \& Applied Earth Sciences,Hydrogeology,Physics,Statistics for Engineering,general},
   month = {5},
   pages = {411-427},
   publisher = {Springer},
   title = {Classical confidence intervals and Bayesian probability estimates for ends of local taxon ranges},
   volume = {21},
   url = {https://link.springer.com/article/10.1007/BF00897326},
   year = {1989},
}
@article{Bradshaw2012,
   author = {C.J.A. Bradshaw and A. Cooper and C.S.M. Turney and B.W. Brook},
   doi = {10.1016/j.quascirev.2011.11.021},
   issn = {02773791},
   journal = {Quaternary Science Reviews},
   month = {2},
   pages = {14-19},
   title = {Robust estimates of extinction time in the geological record},
   volume = {33},
   year = {2012},
}
@article{Solow2006,
   abstract = {The fossil record has been used to shed light on the late Pleistocene megafaunal extinctions in North America and elsewhere. It is therefore important to account for variability due to the incompleteness of the fossil record and error in dating fossil remains. Here, a joint confidence region for the extinction times of horses and mammoths in Alaska is constructed. The results suggest that a prior claim that the extinction of horses preceded the arrival of humans cannot be made with confidence. © 2006 by The National Academy of Sciences of the USA.},
   author = {Andrew R. Solow and David L. Roberts and Karen M. Robbirt},
   doi = {10.1073/PNAS.0509480103/ASSET/28204AEF-4A5A-48F7-A393-CBF144B6A9A3/ASSETS/GRAPHIC/ZPQ01906-2040-M07.JPEG},
   issn = {00278424},
   issue = {19},
   journal = {Proceedings of the National Academy of Sciences of the United States of America},
   keywords = {Extinction times,Radiocarbon dating,Statistical inference},
   month = {5},
   pages = {7351-7353},
   pmid = {16651534},
   publisher = {
National Academy of Sciences},
   title = {On the pleistocene extinctions of Alaskan mammoths and horses},
   volume = {103},
   url = {https://www.pnas.org/doi/abs/10.1073/pnas.0509480103},
   year = {2006},
}
@article{Roberts2003,
   abstract = {The extinction of the dodo (Raphus cucullatus L.; Fig. 1) is commonly dated to the last confirmed sighting in 1662, reported by Volkert Evertsz on an islet off Mauritius1,2. By this time, the dodo had become extremely rare — the previous sighting having been 24 years earlier — but the species probably persisted unseen beyond this date. Here we use a statistical method to establish the actual extinction time of the dodo as 1690, almost 30 years after its most recent sighting.},
   author = {David L. Roberts and Andrew R. Solow},
   doi = {10.1038/426245a},
   issn = {1476-4687},
   issue = {6964},
   journal = {Nature 2003 426:6964},
   keywords = {Humanities and Social Sciences,Science,multidisciplinary},
   month = {11},
   pages = {245-245},
   pmid = {14628039},
   publisher = {Nature Publishing Group},
   title = {When did the dodo become extinct?},
   volume = {426},
   url = {https://www.nature.com/articles/426245a},
   year = {2003},
}
@article{Rule2012,
   abstract = {Giant vertebrates dominated many Pleistocene ecosystems. Many were herbivores, and their sudden extinction in prehistory could have had large ecological impacts. We used a high-resolution 130,000-year environmental record to help resolve the cause and reconstruct the ecological consequences of extinction of Australia's megafauna. Our results suggest that human arrival rather than climate caused megafaunal extinction, which then triggered replacement of mixed rainforest by sclerophyll vegetation through a combination of direct effects on vegetation of relaxed herbivore pressure and increased fire in the landscape. This ecosystem shift was as large as any effect of climate change over the last glacial cycle, and indicates the magnitude of changes that may have followed megafaunal extinction elsewhere in the world.},
   author = {Susan Rule and Barry W. Brook and Simon G. Haberle and Chris S.M. Turney and A. Peter Kershaw and Christopher N. Johnson},
   doi = {10.1126/SCIENCE.1214261/SUPPL_FILE/1214261.RULE.SOM.REVISION.1.PDF},
   issn = {10959203},
   issue = {6075},
   journal = {Science},
   month = {3},
   pages = {1483-1486},
   pmid = {22442481},
   publisher = {American Association for the Advancement of Science},
   title = {The aftermath of megafaunal extinction: Ecosystem transformation in Pleistocene Australia},
   volume = {335},
   url = {https://www.science.org/doi/10.1126/science.1214261},
   year = {2012},
}
@article{Saltre2015,
   abstract = {Accurate estimates of the timing of extinctions (. θ) are critical for understanding the causes of major die-off events and for identifying evolutionary or environmental transitions. Yet many studies have demonstrated that sampling biases and underlying statistical assumptions affect the accuracy of model-based estimates of extinction times (. θ), and the added uncertainty contributed by inherent (laboratory) dating errors has largely been neglected. Here we provide a general guide (model-selection key) for choosing from among eight alternative 'frequentist sampling' (i.e., non-Bayesian) methods, differentiated by their treatment of both the probability of record occurrence and uncertainties in record dates, the most appropriate for a given record. We first provide a methodological framework to characterize time series of dated records as a function of the number of records, the size of the interval between successive records, and laboratory dating errors. Using both simulated data and dated Australian megafauna remains, we then assess how the characteristic of a dataset's time series dictates model performance and the probability of misclassification (false extant vs. false extinct). Among the four classic frequentist methods providing highest model performance, Marshall's (1997) and McCarthy's (1998) methods have the highest model precision. However, high model performance did not prevent misclassification errors, such that the Gaussian-resampled inverse-weighted McInerny (GRIWM) approach is the only method providing both high model accuracy and no misclassification issues, because of its unique down-weighting interval procedure and its ability to account for uncertainties in record dates. Applying the guideline to three time series of extinct Australian species, we recommend using Marshall's, McCarthy's and/or GRIWM methods to infer θ of both Thylacinus sp. and Genyornis sp., because each dataset is characterized by many sightings and a low variance of the interval between records, whereas McInerny's method better suits Diprotodon sp. due to an even lower interval variance.},
   author = {Frédérik Saltré and Barry W. Brook and Marta Rodríguez-Rey and Alan Cooper and Christopher N. Johnson and Chris S.M. Turney and Corey J.A. Bradshaw},
   doi = {10.1016/J.QUASCIREV.2015.01.022},
   issn = {0277-3791},
   journal = {Quaternary Science Reviews},
   keywords = {Dating,Extinction,Model selection key,Sensitivity analysis,Time series},
   month = {3},
   pages = {128-137},
   publisher = {Pergamon},
   title = {Uncertainties in dating constrain model choice for inferring extinction time from fossil records},
   volume = {112},
   year = {2015},
}
@article{Marta2015,
   abstract = {Confidence in fossil ages is a recognized constraint for understanding changes in archaeological and palaeontological records. Poor estimates of age can lead to erroneous inferences-such as timing of species arrival, range expansions and extinctions-preventing robust hypothesis testing of the causes and consequences of past events. Therefore, age reliability must be demonstrated before patterns and mechanisms are inferred. Here we present a generalized quality-rating scheme based on a two-stage set of objective criteria: first, our method assesses the reliability of an age regarding the dating procedure, and second, if the age is based on association, it assesses the confidence in its association with the target vertebrate fossil. We developed this quality rating specifically for Australian applications, but it could be applied to other regions and to longer timescales with some modification. Our method ranks ages in four categories of reliability (A* and A are reliable; B and C are unreliable). In our case study of the late Pleistocene megafauna of Sahul, accounting for reliability (i.e., accepting only reliable ages) reduced the number of useful records within chronologies by 70\%; for most species, this greatly affects any inferences regarding the timing and possible drivers of extinction. Our method provides a simple, replicable and general tool for assessing the age quality of dated fossils, as well as provides a guide for selecting useful protocols and samples for dating.},
   author = {Marta Rodríguez-Rey and Salvador Herrando-Pérez and Richard Gillespie and Zenobia Jacobs and Frédérik Saltré and Barry W. Brook and Gavin J. Prideaux and Richard G. Roberts and Alan Cooper and John Alroy and Gifford H. Miller and Michael I. Bird and Christopher N. Johnson and Nicholas Beeton and Chris S.M. Turney and Corey J.A. Bradshaw},
   doi = {10.1016/J.QUAGEO.2015.08.002},
   issn = {1871-1014},
   journal = {Quaternary Geochronology},
   keywords = {Age reliability,Archaeology,Dating techniques,Fossil deposits,Geochronology,Palaeontology,Quality control,Quaternary},
   month = {10},
   pages = {69-79},
   publisher = {Elsevier},
   title = {Criteria for assessing the quality of Middle Pleistocene to Holocene vertebrate fossil ages},
   volume = {30},
   year = {2015},
}
@article{Johnson2013,
   abstract = {Lima-Ribeiro and Diniz-Filho (2013) present a new compilation and analysis of the chronologies of human arrival and megafaunal extinction throughout the Americas. They find that in many places megafauna were apparently extinct before humans arrived; in many others, megafauna coexisted with humans for thousands of years before going extinct. They conclude that human impact made at most a minor and geographically restricted contribution to megafaunal extinction. We argue that Lima-Ribeiro and Diniz-Filho's (2013) conclusions are unreliable because they have not adequately accounted for uncertainties and biases that affect the estimation of extinction dates from fossil data and human-arrival dates from archeological data. We re-analyze their data taking these problems into account, and reach the opposite conclusion to theirs: extinction consistently followed human arrival with a delay of around one or two thousand years, in agreement with the overkill model of megafaunal extinction. © 2013 Elsevier Ltd and INQUA.},
   author = {Chris N. Johnson and Corey J.A. Bradshaw and Alan Cooper and Richard Gillespie and Barry W. Brook},
   doi = {10.1016/J.QUAINT.2013.06.022},
   issn = {1040-6182},
   journal = {Quaternary International},
   month = {10},
   pages = {273-277},
   publisher = {Pergamon},
   title = {Rapid megafaunal extinction following human arrival throughout the New World},
   volume = {308-309},
   year = {2013},
}
@article{Wang2016,
   abstract = {<p>Because the fossil record is incomplete, the last fossil of a taxon is a biased estimate of its true time of extinction. Numerous methods have been developed in the palaeontology literature for estimating the true time of extinction using ages of fossil specimens. These methods, which typically give a confidence interval for estimating the true time of extinction, differ in the assumptions they make and the nature and amount of data they require. We review the literature on such methods and make some recommendations for future directions.</p>},
   author = {Steve C. Wang and Charles R. Marshall},
   doi = {10.1098/rsbl.2015.0989},
   issn = {1744-9561},
   issue = {4},
   journal = {Biology Letters},
   month = {4},
   pages = {20150989},
   title = {Estimating times of extinction in the fossil record},
   volume = {12},
   year = {2016},
}
@article{Fisher2020,
   author = {Eyal Fisher and Regev Schweiger and Saharon Rosset},
   doi = {10.1080/10618600.2019.1647215},
   issn = {1061-8600},
   issue = {1},
   journal = {Journal of Computational and Graphical Statistics},
   month = {1},
   pages = {140-148},
   title = {Efficient Construction of Test Inversion Confidence Intervals Using Quantile Regression},
   volume = {29},
   year = {2020},
}
@article{Garthwaite1992,
   author = {Paul H. Garthwaite and Stephen T. Buckland},
   doi = {10.2307/2347625},
   issn = {00359254},
   issue = {1},
   journal = {Applied Statistics},
   pages = {159},
   title = {Generating Monte Carlo Confidence Intervals by the Robbins-Monro Process},
   volume = {41},
   year = {1992},
}
@book{Kroese2011,
   author = {Dirk P. Kroese and Thomas Taimre and Zdravko I. Botev},
   doi = {10.1002/9781118014967},
   isbn = {9780470177938},
   month = {2},
   publisher = {Wiley},
   title = {Handbook of Monte Carlo Methods},
   year = {2011},
}
@article{Reimer2020,
    title={The IntCal20 Northern Hemisphere Radiocarbon Age Calibration Curve (0–55 cal kBP)},
    volume={62},
    DOI={10.1017/RDC.2020.41},
    number={4},
    journal={Radiocarbon},
    publisher={Cambridge University Press},
    author={Reimer, Paula J and Austin, William E N and Bard, Edouard and Bayliss, Alex and Blackwell, Paul G and Bronk Ramsey, Christopher and Butzin, Martin and Cheng, Hai and Edwards, R Lawrence and Friedrich, Michael and et al.},
    year={2020},
    pages={725–757}
}
@thesis{Huang2019,
    author={Huang, Arthur},
    title={Estimating the Extinction Time of a Species from the Fossil Record},
    type={Honours},
    institution={University of New South Wales},
    year={2019}
}
@thesis{King2020,
    author={King, Thomas},
    title={Measuring Uncertainty in the Fossil Record},
    type={Masters},
    institution={University of New South Wales},
    year={2020}
}
@article{Carpenter1999,
 ISSN = {13697412, 14679868},
 URL = {http://www.jstor.org/stable/2680743},
 author = {Carpenter, James},
 journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
 number = {1},
 pages = {159--172},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Test Inversion Bootstrap Confidence Intervals},
 urldate = {2022-10-14},
 volume = {61},
 year = {1999}
}

